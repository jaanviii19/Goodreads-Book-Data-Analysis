---
title: "Goodreads Book Data Analysis"
output: html_document
---
### Sumit Dhaundiyal, Janvi Vora - CS544 Term Project
# Dataset Details
### This dataset contains ratings for ten thousand popular books. As to the source, let's say that these ratings were found on the internet. Generally, there are 100 reviews for each book, although some have less - fewer - ratings. Ratings go from one to five. Both book IDs and user IDs are contiguous. For books, they are 1-10000, for users, 1-53424. All users have made at least two ratings. Median number of ratings per user is 8. There are also books marked to read by the users, book metadata (author, year, etc.) and tags. 
# Objective
### The objective of this project is to analyze the reviews given by users on books (goodbooks) and recommend books.

# Separate Dataset Into Their Respective Groups

### We can separate books on the basis of ratings given by the users. The ratings 3 and above can be considered as good/ positive rating. Whereas 2 and below can be considered as bad/ negative rating. Since goodreads doesn't allow to give zero ratings there is no zero rating encountered.

```{r setup, include=FALSE}
require(dplyr)
df <- read.csv("books.csv")
```

```{r}
A=which(is.na(df), arr.ind=TRUE)
print("-----Preprocessing Data-------")
sprintf("Number of NA Values are %d ",length(A))
print("Removing NA Values")
df =df[complete.cases(df),]
summary(df)
```
```{r}
print("We can see that there are years with negative values, Removing all the unacceptable year values")
df<-df[!(df $original_publication_year <=1800),]

```

```{r}
Numerical_data<-df[c(1,5,7,9,13,14,15,16,17,18,19,20,21)]
which(is.na(Numerical_data), arr.ind=TRUE)

print("---------Numerical Data -------- ")
summary(Numerical_data)
pairs(Numerical_data)
```
```{r}
cor(Numerical_data)
```
# We  can see that ratings_count is highly correlated with work_ratings_count, work_text_reviews_count and number of 1,2,3,4 and 5 ratings for each book. Similarly work_ratings_count is also depending on these columns as well.work_text_reviews_count is also, highly correlated with  ratings_count, work_text_reviews_count and number of 1,2,3,4 and 5 ratings for each book.
# Average rating is very important column and is positively correlated with ratings_count,work_ratings_count,work_text_reviews_count 4 ratings and 5 ratings only.
```{r}
library(ggplot2)

ggplot(df, aes(x = average_rating)) + geom_density(na.rm = TRUE, fill = "blue", alpha = 0.3) +
labs(x = "Average Rating") + theme_bw() + ggtitle("Probability Density Distribution of Average Rating")
```
```{r}
barplot(table(Numerical_data $average_rating),
 main="Average Rating Count",
 xlab="Rating",
 ylab="Count",
 border="black",
 col="Coral",
 density=10
 )

```
```{r}
#install.packages("tidyverse")
library(tidyverse)
```

```{r}

print("Plotting Language Code of the Books by percentage")

df %>%
    group_by(language_code) %>%
    summarize(count = length(language_code), perc = paste(round(count / nrow(df) * 100, 2),"%")) %>%
    arrange(desc(count)) %>%
    top_n(10) %>%
    ggplot(aes(x = reorder(language_code, -count), y = count, label = perc)) + geom_col(fill = "blue", alpha = 0.3) + 
    geom_label(nudge_y = 300) +
    labs(x = "Languange Code", y = "Number of Books") + theme_bw() +
    ggtitle("Language Distribution")

```
```{r}
print("Plotting Publication years of the Books by percentage")
df %>%
    group_by(original_publication_year) %>%
    summarize(count = length(original_publication_year), perc = paste(round(count / nrow(df) * 100, 2),"%")) %>%
    arrange(desc(count)) %>%
    top_n(10) %>%
    ggplot(aes(x = reorder(original_publication_year, -count), y = count, label = perc)) + geom_col(fill = "blue", alpha = 0.3) + 
    geom_label(nudge_y = 300) +
    labs(x = "Publication Year", y = "Number of Books") + theme_bw() +
    ggtitle("Publication Year Distribution")
quartz.save("PublicationYear.pdf", type="pdf");


```
```{r}
print("Plotting Authors of the Books by percentage")
df %>%
    group_by(authors) %>%
    summarize(count = length(authors), perc = paste(round(count / nrow(df) * 100, 2),"%")) %>%
    arrange(desc(count)) %>%
    top_n(10) %>%
    ggplot(aes(x = reorder(authors, -count), y = count, label = perc)) + geom_col(fill = "blue", alpha = 0.3) + 
    geom_label(nudge_y = 300) +
    labs(x = "Authors", y = "Number of Books") + theme_bw() +
    ggtitle("Authors Distribution")

```
```{r}
print("Publication Year")
hist(Numerical_data$original_publication_year)
ggplot(Numerical_data, aes(x = original_publication_year)) + geom_density(na.rm = TRUE, fill = "blue", alpha = 0.3) +
labs(x = "Publication Year") + theme_bw() + ggtitle("Probability Density Distribution of Publication Year")
```
# We can see that the plot is Left skewed, The peek is around year 2004
```{r}
print("Plotting Desity Graph for Average Ratings of books")
```


```{r}
ggplot(Numerical_data, aes(x = average_rating)) + geom_density(na.rm = TRUE, fill = "blue", alpha = 0.3) +
labs(x = "Average Rating") + theme_bw() + ggtitle("Probability Density Distribution of Average Rating")

```

```{r}
print("Publication Year has left skewed Distribution")
print("Central Limit Theorem on Publication Year")
print("Mean of Publication Yea is")
mean(df$original_publication_year)

hist(df$original_publication_year,col = "cyan",main = "Histogram for Publication Year",xlab = "Publication Year")
abline(v=12.8,col="red",lty=1)
```
```{r}
print("Rating count has right skewed Distribution")

print("Central Limit Theorem on Rating Count")
print("Mean of Rating Count per book is")
mean(df$ratings_count)

hist(df$ratings_count,col = "cyan",main = "Histogram for Rating Counts per book",xlab = "Rating Count")
abline(v=12.8,col="red",lty=1)
ggplot(Numerical_data, aes(x = ratings_count)) + geom_density(na.rm = TRUE, fill = "blue", alpha = 0.3) +
labs(x = "Rating Count") + theme_bw() + ggtitle("Probability Density Distribution of Rating Counts")

```

```{r}
s30<-c()
n=9000
for (i in 1:n) {
s30[i] = mean(sample(df$ratings_count,30, replace = TRUE))}
hist(s30, col ="lightgreen", main="Sample size =30",xlab = "Rating Count")
abline(v = mean(s30), col = "Red")
abline(v = 12.8, col = "blue")

print("We can see that when we will draw sufficient samples of size 30, calculate their means, and plot them. We get graph approaching Normal distribution curve. Hence, The central Limit Theorem Can be applied here")

```
```{r}
print("Increasing size of samples")
s30 <- c()
s50 <- c()
s500 <- c()
s1000 <- c()
s1500 <- c()
n =9000
for ( i in 1:n){
s30[i] = mean(sample(df$ratings_count,30, replace = TRUE))
s50[i] = mean(sample(df$ratings_count,50, replace = TRUE))
s500[i] = mean(sample(df$ratings_count,500, replace = TRUE))
s1000[i] = mean(sample(df$ratings_count,1000, replace = TRUE))
s1500[i] = mean(sample(df$ratings_count,1500, replace = TRUE))

}
par(mfrow=c(1,5))
hist(s30, col ="lightblue",main="Sample size=30",xlab ="Rating Count")
abline(v = mean(s30), col = "red")

hist(s50, col ="lightgreen", main="Sample size=50",xlab ="Rating Count")
abline(v = mean(s50), col = "red")

hist(s500, col ="orange",main="Sample size=500",xlab ="Rating Count")
abline(v = mean(s500), col = "red")
hist(s1000, col ="navy",main="Sample size=1000",xlab ="Rating Count")
abline(v = mean(s500), col = "red")
hist(s1500, col ="black",main="Sample size=1500",xlab ="Rating Count")
abline(v = mean(s500), col = "red")

print("As sample sizes grow, we get a decent bell-shaped curve and the sampling distribution approaches normal distribution")
```

```{r}
print("Generating Recommendation based on names")
#nstall.packages("pacman")
pacman::p_load(tm)
library(tm)

```
```{r}
df$Recommendation_based_on_Title<-NA

for (row in 1: nrow(df)) {
Title <- df[row, "original_title"]
Title<-str_replace_all(Title, "[^[:alnum:]]", " ")
Title<-str_replace_all(Title, "The", "")
Title<-str_replace_all(Title, "the", "")
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
Title <- stringr::str_replace_all(Title, stopwords_regex, '')
result <- strsplit(Title,"[[:space:]]")
if (length(result[[1]])<1){
df[row, "Recommendation_based_on_Title"]<-NA
}
else{
Book_rec  <- df[rowSums(sapply(result[[1]], grepl, df$original_title)) > 0, , drop = FALSE]
rec<-as.list(Book_rec$original_title[1:3])
df[row, "Recommendation_based_on_Title"]<-toString(rec)
}
}
```
```{r}
for (row in 1: nrow(df))  {
Author <- df[row, "authors"]
Auth<- df[df$authors %in% Author,]
#print(Auth)
AuthList<- Auth$original_title
rec<-as.list(AuthList[1:5])
df[row, "Recommendation_based_on_Author "]<-toString(rec)
}
print("New Parameter Recommendation_based_on_Author added,which gives other books of same Author")
head(df)
```

